##High-level functions for CRDS water isotope data reduction

#Write configuration file
write_config = function(){
  fp = readline("File path containing CRDS data directories: \n")
  rf = readline("Reference file with full path: \n")
  op = readline("File path for excel output: \n")
  usr = readline("Analyst email: \n")
  
  
  cf = file("~/.crds.config", open = "wt")
  writeLines(paste0("dataPath=", fp), cf)
  writeLines(paste0("refFile=", rf), cf)
  writeLines(paste0("outPath=", op), cf)
  writeLines(paste0("user=", usr), cf)
  close(cf)
}

# Retrieve file names for a given machine and date
file_lookup <- function(instrument, runDate){
  ## machine is the serial number of a Picarro instrument formatted 
  ## to match the formatting of the Dropbox file for that instrument
  ## (ie. hids2053, hids2052 or hids2046)
  cfg = init()
  
  if(nchar(runDate) != 10){stop("runDate format must be YYYY-MM-DD")}
  runDate = paste0(substr(runDate, 3, 4), substr(runDate, 6, 7), 
                   substr(runDate, 9, 10))
  ## change runDate to format yymmdd (eg. 150310)
  
  data.files <- list.files(paste(cfg$dataPath, instrument, sep = "/"), 
                           full.names=TRUE)
  ## returns list of files for the specified machine
  
  ids.files <- list.files(paste(cfg$dataPath, instrument,"runfiles", sep = "/"), 
                          full.names=TRUE)
  ## returns list of files in the 'runfiles' folder for the 
  ## specified machine, ie. the sample ids
  
  data.file <- tail(grep(runDate, data.files, value=TRUE), 1)
  ## returns filepath for last isotope file generated
  ## for the specified machine on the specified date

  ids.file <- tail(grep(runDate, ids.files, value=TRUE), 1)
  ## returns filepath for the last file with sample identifiers 
  ## for the specified machine on the specified date
  
  print(list(data.file=data.file,ids.file=ids.file))
  return(list(data.file=data.file,ids.file=ids.file))
}

#Check the data & ids files and return warnings
check_files <- function(files){
  ## filenames is a list with filenamea for a data file & a sample
  ## ids file, such as that generated by the file.lookup function
  
  ## reads in the data csv  
  data <- read.csv(files$data.file, stringsAsFactors=FALSE, 
                   strip.white=TRUE)

  ## checks that the necessary columns are present and returns
  ## error if not
  if(any(c("Port", "Inj.Nr", "d.18_16.Mean", "d.D_H.Mean") 
         %in% names(data) == FALSE)) { 
    stop("data file is not correctly formatted, check that the 
            machine and date are correct and check file format")
  } else {
    message("data file format correct")
  }
  
  if(nrow(data) < 41){
    stop("only reference water data")
  }
  
  # stores outlier/omit index info
  oi = c(rep(FALSE, 10), rep(TRUE, nrow(data)-10))
  
  # set oi flag for missing lines
  oi[is.na(data$H2O_Mean)] = FALSE
  
  # empty or missing lines
  ml_1 = data$Port[!oi]
  ml_2 = data$Inj.Nr[!oi]
  ml = paste0(ml_1, "#", ml_2)
  if(length(ml) > 10){
    ml = ml[11:length(ml)]
    ml = paste(ml, collapse = ", ")
    warning("the following injections are missing:")
    warning(ml)
  }

  ## reads in sample ids file
  ids <- read.csv(files$ids.file,stringsAsFactors=FALSE, 
                  strip.white=TRUE)
  
  ## renames columns
  names(ids) <- c("Tray","Port","ID","ID2")
  
  ## checks formatting of sample ids table and returns warnings
  ## as to wehter it is correctly formatted or not
  if(length(colnames(ids))!=4 | is.numeric(ids[,2])==FALSE | 
       is.character(ids[,3])==FALSE) {
    stop("ids file is not correctly formatted, check that the 
            machine and date are correct, that the file is named 
            correctly, and that the file is correctly formatted")
  } else {
    message("ids file format correct")
  }
  
  ## identifies the numeric part of the port column and converts
  ## it to numeric data
  data$Port<-as.numeric(regmatches(data$Port,regexpr(
    "[0-9][0-9]", data$Port)))
  
  ## creates a table with the frequency of each port in the data
  ## table
  data.ports.freq <- as.data.frame(table(data$Port))
  
  ## renames the columns in the frequency table
  names(data.ports.freq) <- c("Port","Freq")
  
  ## converts port column to numeric data
  data.ports.freq$Port <- as.numeric(data.ports.freq$Port)
  
  ## checks if any ports have less than the required number
  ## of injections and returns warnings to indicate whether
  ## they do or not
  if(any(data.ports.freq$Freq[data.ports.freq$Port>4] < 4) | 
       any(data.ports.freq$Freq[data.ports.freq$Port<=4] < 10)) {
    warning("Missing rows in data") 
  } else {
    message("data file complete")
  }
  
  ## generates unique list of ports in the sample ids table
  id_ports <- unique(ids$Port)
  
  ## checks that the ports listed in the sample ids table and the 
  ## data table are the same and returns warnings to indicate 
  ## whether they do or not
  if(any(id_ports %in% data.ports.freq$Port == FALSE) |
       any(data.ports.freq$Port %in% id_ports == FALSE)) {
    warning("Ports are not the same for data.file and ids.file, 
            check them and ensure they are the same before running 
            function process.data") 
  } else {
    message("ids match")
  }
  
  files$oi = oi
  return(files)
}

process_data <- function(files){
  ## filenames is a list with filenamea for a data file & a sample
  ## ids file, such as that generated by the file.lookup function

  #Read in reference calibration and QA parameters
  cfg = init()
  refs = refRead(cfg$refFile)
  
  ## data.mod function modifies & merges the data & sample ids files
  df <- data.mod(data.file = files$data.file, 
                 ids.file = files$ids.file)
  
  # add sequence number per injection
  df$seqN = seq_along(df[,1])
  
  # pull out outlier/omit index
  oi = files$oi
  
  # continue the mdo cycle?
  mdo = TRUE
  
  #initial memory parameter guesses
  n = seq(1:8)
  o.mc = exp(-n) / 8
  h.mc = exp(-n) / 4
  mem = list(o.mc = o.mc, h.mc = h.mc)
  
  # cycle to fit/apply memory and drift corrections,
  # remove outliers, and repeat corrections 
  while(mdo){
    ## generate memory-correction terms for the data
    mem <- mc.terms(df, mem, oi)
    
    ## apply memory-correction terms to the d18O data
    df$d18O_mc <- mc.corr(df, mem$o.mc, "O", oi)
    
    ## apply memory-correction terms to the d2H data
    df$d2H_mc <- mc.corr(df, mem$h.mc, "H", oi)
    
    ## drift.reg function calculates regression of the  
    ## slrm data against sequence number
    drift <- drift.reg(df, refs, oi)
    
    ## data.dc function applies the drift corrections to the data
    dc <- data.dc(df,drift)
    
    ## outlier detections
    oi.in = oi
    oi = outlier(dc, oi.in)
    if(all(oi.in == oi)){
      mdo = FALSE
    }
  }
  
  message("MDO operations completed")
  dc$Outlier = !oi

  ## collapse values to average per port
  da = collapse(dc, oi)

  ## cal.reg function calculates a regression line using the known & 
  ## measured values for the d18O & d2H data separately
  cal <- cal.reg(da, refs)
  
  ## calibrates the d18O and d2H data
  d18O_cal = data.cal(da, "O", cal)
  d2H_cal = data.cal(da, "H", cal)

  ## combine calibrated data with da
  dcal = cbind(da, d18O_cm = d18O_cal$calMean, 
               d18O_csd = d18O_cal$calSD,
               d2H_cm = d2H_cal$calMean, d2H_csd = d2H_cal$calSD)
  
  # update message
  message("Calibration completed")

  flagged <- qa.flag(dcal, refs)
  ## qa.flag function evaluates the data against the predetermined
  ## qa cutoffs and flags 
  
  ## qa.summary function summarizes the qa metrics for the run
  qa.report <- qa.summary(files$data.file, refs, mem, drift,
                          cal, flagged)

  ## build up dataframe comparing known and measured LRM values
  ref.df = flagged[flagged$Port %in% c(2:4), c(2, 8, 6, 9, 10, 7, 11)]
  ref.comp.o = merge(ref.df[,1:4], refs$refs[,1:3])
  ref.comp.h = merge(ref.df[,c(1, 5:7)], refs$refs[,c(1, 4:5)])
  ref.comp = merge(ref.comp.o, ref.comp.h)
  ref.comp[, 2:11] = round(ref.comp[, 2:11], 2)
  
  samples.summary <- flagged[!(flagged$ID %in% refs$refs[,"ID"]),]
  ## subsets flagged df to include only non-reference data
  
  slrm.summary <- flagged[flagged$ID == refs$refs["slrm","ID"],]
  ## subsets flagged df to inlcude only data for slrm
  
  ref.all <- dc[dc$ID %in% refs$refs[,"ID"],]
  ## subsets df to include only data for references
  
  data.all <- dc[!(dc$ID %in% refs$refs[,"ID"]),]
  ## subsets df to include only non-reference data
  
  #update message
  message("QA/QC screening completed")
  
  return(list(samples.summary = samples.summary, 
              slrm.summary = slrm.summary, 
              ref.all = ref.all, 
              data.all = data.all, 
              qa.report = qa.report, 
              ref.compare = ref.comp))
}


#Format the dataframes from process.crds for printing to the console
print_format <- function(data){
  ## data is a list of dataframes such as that created by the 
  ## process.crds function that includes qa.report & samples.summary
  
  qa.print <- data$qa.report
  ## stores the dataframe qa.report
  
  qa.print$value[3:20] <- round(as.numeric(qa.print$value[3:20]),3)
  ## rounds all of the numeric values in qa.print to 3 decimals

  samples.s <- data$samples.summary
  ## stores the dataframe samples.summary

  samples.s <- samples.s[,c("Port","ID","ID2","d18O_cm", "d2H_cm",
                          "d18O_csd","d2H_csd","ignore_run",
                          "ignore_sample")]
  ## subsets the dataframe to include only certain columns

  names(samples.s)[4:7] <- c("d18O", "d2H", "d18O SD", "d2H SD")
  ## renames columns 4 & 5

  samples.s[,4:7] <- round(samples.s[,4:7],2)
  ## rounds columns 4-7 to 2 decimal places
  
  #typecast Port to numeric and sort
  samples.s$Port = as.numeric(samples.s$Port)
  samples.s = samples.s[order(samples.s$Port),]

  return(list(qa = qa.print, samples.summary = samples.s))
}

#Plot sample results against GMWL for review
plot_gmwl <- function(data){
  ## data is a dataframe such as the samples.summary table created
  ## by the print.format function
  
  o <- c(min(data$d18O,na.rm=T),max(data$d18O,na.rm=T))
  ## creates a vector with the minimum and maximum d18O values
  
  h <- o*8+10
  ## creates a vector with result of multiplying the minimum and 
  ## maximum d18O values by 8 and adding 10
  
  reg <- lm(h~o)
  ## calculates regression for o & h
  
  h.min <- if(h[1] < min(data$d2H,na.rm=T)){h[1]
  } else {min(data$d2H,na.rm=T)}
  ## compares the minimum calculated value to the minimum measured 
  ## value and returns the lowest of the 2 to be used to set the
  ## plotting boundaries
  
  h.max <- if(h[2] > max(data$d2H,na.rm=T)){h[2]
  } else {max(data$d2H,na.rm=T)}
  ## compares the maximum calculated value to the maximum measured 
  ## value and returns the greatest of the 2 to be used to set the
  ## plotting boundaries
  
  plot(data$d18O,data$d2H,main="d18O v. d2H with GMWL",xlim = o, 
       ylim = c(h.min,h.max), xlab="d18O",ylab="d2H")
  abline(reg)
}

#Print data summaries for review by analyst
review_data <- function(data){
  ## data is a list of dataframes such as that created by the 
  ## process.crds function that includes qa.report & samples.summary
  
  print.me <- print_format(data)
  ## runs print.format function

  plot_gmwl(print.me$samples.summary)
  ## runs plot.gmwl function
  
  print(list(qa = print.me$qa,
           data = print.me$samples.summary))
}

#Push sample data and parameter values to wiDB
db <- function(data, analyst){
  ## data is a list of dataframes such as that created by the 
  ## process.data function that includes qa.report & samples.summary

  qa <- data$qa.report
  ## stores the qa.report table
  
  Instrument <- qa$value[1]
  ## stores the instrument name
  
  Run_date <- qa$value[2]
  Run_date = as.Date(Run_date, format = "%m/%d/%y")
  ## stores the run date
  
  channel = odbcConnect("WIDB")
  ## creates a connection to the database, must be loaded as ODBC source w/ this name

  existing <- sqlQuery(channel, paste0("SELECT * FROM Parameters_table 
               WHERE Instrument = '",Instrument, "' AND 
               Run_date = '",Run_date,"'"))
  ## creates a table with data that matches the instrument and
  ## run date if it exists

  if(nrow(existing)>0){
    vdupes = readline(prompt="Duplicate run entry found in database. View (Y/N)?")
    if(vdupes!="N") print(existing)
    ddupes = readline(prompt="Delete (Y/N)?")
    if(ddupes=="Y"){ 
      sqlQuery(channel, paste0("DELETE FROM Parameters_table WHERE Instrument = '", 
                               Instrument, "' AND Run_date = '", Run_date, "'"))
    } else {stop("data already present in database, no new data imported")}
  }
  ## finds duplicates in the existing table and prompts for user prefered action 
  
  n1 = sqlQuery(channel, "SELECT COUNT(*) FROM Parameters_table")
  sqlQuery(channel,paste0("INSERT INTO Parameters_table(Instrument,
    Run_date, Memory1_O, Memory2_O, Memory3_O, Memory4_O, Drift1_O, 
    Slope_O, Intercept_O, Memory1_H, Memory2_H, Memory3_H, Memory4_H, 
    Drift1_H, Slope_H, Intercept_H, PT_O_ave, PT_H_ave, PT_O_sd, PT_H_sd, 
    PT_count, Ignore_run, Analyst) 
                        VALUES('",Instrument,"','", Run_date,"',",
                        qa$value[3], ",", qa$value[4], ",", 
                        qa$value[5], ",", qa$value[6],",",
                        qa$value[7], ",", qa$value[8], ",",
                        qa$value[9], ",", qa$value[10], ",",
                        qa$value[11], ",", qa$value[12],",",
                        qa$value[13], ",", qa$value[14], ",",
                        qa$value[15], ",", qa$value[16], ",",
                        qa$value[17], ",", qa$value[18],",",
                        qa$value[19], ",", qa$value[20], ",",
                        qa$value[21], ",", qa$value[22], ", '",
                        analyst, "')"))
  ## writes data to the Parameters_table in the database
  n2 = sqlQuery(channel, "SELECT COUNT(*) FROM Parameters_table")
  print(paste(n2-n1, "parameter set imported"))
  
  s <- data$samples.summary
  ## stores the samples.summary table
  
  s$Ignore <- ifelse(s$ignore_run == 1 | s$ignore_sample == 1, 1, 0)
  ## creates a single column that determines whether a sample should be ignored
  
  for (i in 1:nrow(s)){
    if(!is.na(s$ID2[i]) && s$ID2[i] != ""){
      s$Sample_ID[i] = paste0(s$ID2[i], "_", s$ID[i])
    } else {
      s$Sample_ID[i] = as.character(s$ID[i])
    }
  }
  ## creates a single column that stores composite ID
  
  existing = sqlQuery(channel, "SELECT * FROM Water_Isotope_Data WHERE Sample_ID = NULL")
  for(i in 1:nrow(s)){
    existing = rbind(existing, sqlQuery(channel, paste0("SELECT * FROM Water_Isotope_Data 
               WHERE WI_Analysis_Instrument = '", Instrument, "' AND 
               WI_Analysis_Date = '", Run_date,"' AND Sample_ID = '", s$Sample_ID[i], "'")))
  }
  if(nrow(existing)>0){
    vdupes = readline(prompt="Duplicate sample data found in database. View (Y/N)?")
    if(vdupes!="N") print(existing)
    ddupes = readline(prompt="Delete (Y/N)?")
    if(ddupes=="Y"){ 
      for(i in 1:nrow(existing)){
        sqlQuery(channel, paste0("DELETE FROM Water_Isotope_Data WHERE WI_Analysis_ID = '", existing$WI_Analysis_ID[i], "'"))
      }
    } else {stop("data already present in database, no new data imported")}
  }
  ## creates a table with data that matches the instrument, run date,
  ## and sample ID if it exists

  wids = sqlQuery(channel, "SELECT WI_Analysis_ID FROM Water_Isotope_Data WHERE WI_Analysis_ID LIKE 'SPATIAL%'")
  wid_nums = as.integer(substring(wids$WI_Analysis_ID, regexpr("_", wids$WI_Analysis_ID)+1))
  widmax = max(wid_nums)
  ## retrieves analysis IDs for SPATIAL samples and finds maximum value

  n1 = sqlQuery(channel, "SELECT COUNT(*) FROM Water_Isotope_Data")
  for(i in 1:nrow(s)){
    qstring = paste0("INSERT INTO Water_Isotope_Data (WI_Analysis_ID, Sample_ID, d2H, d18O, d2H_Analytical_SD, d18O_Analytical_SD, WI_Analysis_Date, WI_Analysis_Source, WI_Analysis_Instrument, WI_Analysis_Ignore)
           VALUES('SPATIAL_", widmax+i, "', '", s$Sample_ID[i], "', ", s$d2H_dc[i], ", ", s$d18O_dc[i], ", ", s$d2H_sd[i], ", ", s$d18O_sd[i], ", '", Run_date, "', 'SPATIAL','",  Instrument, "', ", s$Ignore[i], ")")
    qstring = gsub(",NaN,", ",NULL,", qstring)
    qstring = gsub(",NA,", ",NULL,", qstring)
    sqlQuery(channel, qstring)
  }
  n2 = sqlQuery(channel, "SELECT COUNT(*) FROM Water_Isotope_Data")
  print(paste(nrow(s), "samples in file"))
  print(paste(n2-n1, "samples imported"))
  ## writes data to the DB table, analysis ID is autogenerated with prefix and 
  ## incremented integer suffix 

close(channel)
## closes the connection to the database
}

#Write tables to tabs in xlsx file for backup/archive
excel <- function(files, data){
  ## file is the filename of a csv with sample ids formatted 
  ## with the date, sample description, and machine name (e.g. 
  ## 150310_SIRFER 14-217_HIDS2046.csv)
  ## data is a list of dataframes such as that created by the 
  ## process.crds function that includes 6 tables
  cfg = init()

  chunks = unlist(strsplit(files$ids.file, "/"))
  output_file = paste0(cfg$outPath, "/", chunks[length(chunks)])
  ## creates a filename to be used for the excel file by modifying
  ## the sample ids filename
  
  output_file <- sub(".csv",".xlsx",output_file)
  ## modifies output_file with the correct file extension
  
  if(file.exists(output_file)){file.remove(output_file)}
  ## removes the output_file if it already exists
  
  wb <- createWorkbook()
  ## creates an empty excel workbook
  
  lapply(names(data), function(x) addWorksheet(wb, sheetName=x))
  ## creates one tab in the workbook for each of the tables
  ## in data
  
  lapply(names(data), function(x) writeData(wb, sheet=x, data[[x]]))
  ## writes each table in data to corresponding worksheet

  saveWorkbook(wb, output_file)
  ## saves the excel workbook to the filename specified by
  ## output_file
  
}
